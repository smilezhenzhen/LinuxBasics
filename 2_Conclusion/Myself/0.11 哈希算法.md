---
typora-copy-images-to: assets
---

#### 0 什么是哈希算法

将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值。优质的哈希算法需满足以下几点要求：

- 从哈希值不能反向推导出原始数据，所以哈希算法也叫作单项哈希算法；
- 对输入数据非常敏感，哪怕原始数据值修改了一个bit，最后得到的哈希值也大不相同；
- 散列冲突有的概率要小，对于不同的原始数据，哈希值相同的概率非常小；
- 哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。

哈希算法的应用非常多，选用最常用的七个进行介绍，分别是：安全加密、唯一标识、数据校验、散列函数、负载均衡、数据分片、分布式存储。

#### 1 应用之一：安全加密

最长用于加密的哈希算法是：MD5(MD5 Message-Digest Algorithm,MD5消息摘要算法)和SHA(Secure Hash Algorithm, 安全散列算法)，以及DES数据加密标准和AES高级加密标准。

用于加密的哈希算法需满足两点：①很难根据哈希值反向推导出原始数据，②散列冲突的概率要很小。没有绝对安全的加密，越复杂、越难破解的加密算法，需要的计算时间也越长，密码学界一直致力于找到一种快速并且很难被破解的哈希算法，在实际开发中也需要权衡破解难度和计算时间，来决定究竟使用哪种加密算法。

如果用户数据被“脱库”，黑客虽然拿到的是加密后的密文，但可通过猜的方式来破解密码，因为用户的密码太简单，000000/123456这些简单的数据组合。通过维护一个常用密码的字典表，把字典中每个密码用哈希算法计算哈希值，然后通过哈希值跟脱库后的密文比对，如果相同就基本认为两个密码相同。安全和攻击是一种博弈关系，不存在绝对的安全，所谓的安全措施只是增加攻击哦成本而已。

#### 2 应用之二：唯一标识

以识别图片为例，给每个图片取一个唯一标识或者说摘要信息，通过哈希算法得到一个哈希字符串，用它作为图片的唯一标识，通过这个唯一标识来判定图片是否在图库中。

#### 3 应用之三：数据校验

以下载电影为例，BT下载的原理是基于P2P协议的，一个2GB的电影被分割为100块20MB的文件块。为了确定下载的文件是否被宿主机机器恶意修改过，如何来校验文件块的安全、正确和完整呢。可以对这100个文件块分别取哈希值，并保存在种子文件中。只要文件块的内容有一丁点的改变，最后计算出的哈希值就会不同。当下载完成之后，可通过相同的哈希算法对下载好的文件块逐一求哈希值，然后对种子文件中保存的哈希值比对。如果不同即说明这个文件块不完整或者被篡改了。

#### 4 应用之四：散列函数

散列函数对于散列算法冲突的要求较低，对于是否能反向解密也不在意，更加关注散列后的值是否能均匀分布，一组数据能否均匀地散列在各个槽中，散列函数比较最求效率。

#### 5 应用之五：负载均衡

如何实现一个会话粘滞的负载均衡算法，即需要在同一个客户端上，一次会话中的所有请求都路由到同一个服务器上。

通过哈希算法，对客户端IP地址或者会话ID计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。即将同一个IP过来的请求都路由到同一个后端服务器上。

#### 6 应用之六：数据分片

##### 6.1 如何统计搜索关键词出现的次数

针对记录了用户搜索关键词的IT的日志文件，想要快速统计出每个关键词被搜索的次数。可先对数据进行分片，然后采用多台机器处理的方法来提高处理速度。用N台机器冰箱处理，从搜索记录的日志文件中，以此读取每个搜索关键词，通过哈希函数计算哈希值，再跟N取模，最终得到的值即为应该被分配的机器编号。这样哈希值相同的搜索关键词就被分配到了同一个机器上，即同一个搜索关键词被分配到同一个机器上。这个处理过程即为MapReduce的基本设计思想。

##### 5.2 如何快速判断图片是否在图库中

同样对图片的标识数据进行分片，然后采用多机处理。针对海量数据的处理问题，都可采用多机分布式处理。借助分片的思想，可突破单片机内存、CPU等资源的限制。

#### 7 应用之七：分布式存储

该如何决定将哪个数据放在哪个机器上呢，可利用数据分片的思想，通过哈希算法对数据取哈希值，然后对机器个数取模，最终得到的即为应该存储的缓存机器编号。但是如果此时增加机器就会导致所以数据该存放机器的编号发生改变，要发生大量数据搬移，显然是不可取的。这就要用到一致性哈希算法。

假设我们有 k 个机器，数据的哈希值的范围是 [0, MAX]。我们将整个范围划分成 m 个小区间（m 远大于 k），每个机器负责 m/k 个小区间。当有新机器加入的时候，我们就将某几个小区间的数据，从原来的机器中搬移到新的机器中。这样，既不用全部重新哈希、搬移数据，也保持了各个机器上数据数量的均衡。